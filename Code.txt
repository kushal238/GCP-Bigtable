# load_data.py
import csv
import datetime
import os
from google.cloud import bigtable

# Configuration
PROJECT_ID = "elevated-nature-443722-s9"
INSTANCE_ID = "ev-bigtable"
TABLE_ID = "ev-population"
COLUMN_FAMILY_ID = "ev_info"
CSV_FILE_PATH = "Electric_Vehicle_Population_Data.csv"
BATCH_SIZE = 1000

# Bigtable Connection
print("Connecting to Bigtable...")
try:
    client = bigtable.Client(project=PROJECT_ID, admin=True)
    instance = client.instance(INSTANCE_ID)
    table = instance.table(TABLE_ID)
    print(f"Successfully connected to Bigtable instance '{INSTANCE_ID}' and table '{TABLE_ID}'")
except Exception as e:
    print(f"Error: Could not connect to Bigtable.")
    print(f"Details: {e}")
    exit()

# Data Loading
rows_to_mutate = []
rows_processed = 0
rows_skipped = 0

print(f"\nStarting data loading from '{CSV_FILE_PATH}'...")

try:
    with open(CSV_FILE_PATH, mode='r', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        # Assuming headers in the file exactly match these:
        required_headers = ['DOL Vehicle ID', 'Make', 'Model', 'Model Year', 'Electric Range', 'City', 'County']
        header = reader.fieldnames

        if not header:
            print(f"Error: Could not read header row from CSV file '{CSV_FILE_PATH}'.")
            exit()
        print("Processing rows...")

        for row_data in reader:
            try:
                row_key_str = row_data.get('DOL Vehicle ID', '').strip()
                if not row_key_str:
                    rows_skipped += 1
                    continue

                # Encode strings to bytes for Bigtable library (using UTF-8 is standard)
                row_key_bytes = row_key_str.encode('utf-8')
                make = row_data.get('Make', '').strip().encode('utf-8')
                model = row_data.get('Model', '').strip().encode('utf-8')
                model_year = row_data.get('Model Year', '').strip().encode('utf-8')
                electric_range = row_data.get('Electric Range', '').strip().encode('utf-8')
                city = row_data.get('City', '').strip().encode('utf-8')
                county = row_data.get('County', '').strip().encode('utf-8')

                # Create Bigtable Row Mutation
                row_mutation = table.direct_row(row_key_bytes)

                # Set cell values
                row_mutation.set_cell(COLUMN_FAMILY_ID, b'make', make)
                row_mutation.set_cell(COLUMN_FAMILY_ID, b'model', model)
                row_mutation.set_cell(COLUMN_FAMILY_ID, b'model year', model_year)
                row_mutation.set_cell(COLUMN_FAMILY_ID, b'electric range', electric_range)
                row_mutation.set_cell(COLUMN_FAMILY_ID, b'city', city)
                row_mutation.set_cell(COLUMN_FAMILY_ID, b'county', county)

                rows_to_mutate.append(row_mutation)
                rows_processed += 1

                # Send Batch Mutation
                if len(rows_to_mutate) >= BATCH_SIZE:
                    table.mutate_rows(rows_to_mutate)
                    rows_to_mutate = []

            except Exception as e:
                # Catch errors during processing of a single row
                print(f"Warning: Error processing row with key '{row_key_str}': {e}. Skipping row.")
                rows_skipped += 1

    # Mutate Final Batch
    if rows_to_mutate:
        print(f"Mutating final batch of {len(rows_to_mutate)} rows (Total processed: {rows_processed})...")
        table.mutate_rows(rows_to_mutate)

    # Completion Summary
    print("\n--------------------------------------------------")
    print("Finished loading data.")


except FileNotFoundError:
    print(f"\nError: The file '{CSV_FILE_PATH}' was not found.")
    print("Please ensure the CSV file exists in the same directory as the script.")
except Exception as e:
    # General catch block for other errors (like potential UnicodeDecodeError)
    print(f"\nAn unexpected error occurred:")
    print(f"Details: {e}")


# app.py
import datetime
import os
from flask import Flask, jsonify
from google.cloud import bigtable
from google.cloud.bigtable.row_filters import ColumnQualifierRegexFilter, CellsRowLimitFilter

# Flask App Initialization
app = Flask(__name__)

# Bigtable Configuration
PROJECT_ID = "elevated-nature-443722-s9" # Project ID set by user
INSTANCE_ID = "ev-bigtable"

# Bigtable Client Initialization
try:
    client = bigtable.Client(project=PROJECT_ID, admin=True)
    instance = client.instance(INSTANCE_ID)
    table = instance.table("ev-population")
    print(f"Successfully connected to Bigtable: {PROJECT_ID}/{INSTANCE_ID}/{"ev-population"}")
except Exception as e:
    print(f"Error connecting to Bigtable: {e}")
    client = None
    instance = None
    table = None

# Helper function to read all row keys
def get_all_row_keys(cbt_table):
    row_filter = CellsRowLimitFilter(1)
    try:
        for row in cbt_table.read_rows(filter_=row_filter):
            yield row.row_key
    except Exception as e:
        print(f"Error reading row keys: {e}")
        raise

# API Endpoints

@app.route('/')
def index():
    return "EV Population Bigtable Query API"

@app.route('/rows')
def get_total_rows():
    if not table: return "Error: Bigtable connection not established", 500
    print("Processing /rows request...")
    count = 0
    try:
        for _ in get_all_row_keys(table):
            count += 1
        print(f"/rows count: {count}")
        return str(count)
    except Exception as e:
        print(f"Error in /rows: {e}")
        return "Error processing request", 500


@app.route('/Best-BMW')
def get_best_bmw_count():
    if not table: return "Error: Bigtable connection not established", 500
    print("Processing /Best-BMW request (Full Client-side filter)...")
    count = 0
    rows_processed = 0
    bmws_found = 0
    try:
        for row in table.read_rows():
            rows_processed += 1
            try:
                family_data = row.cells.get("ev_info", {}) 
                make_cell = family_data.get(b'make')
                range_cell = family_data.get(b'electric range') 

                if not make_cell or not range_cell:
                    continue

                make = make_cell[0].value.decode('utf-8')
                if make.lower() == 'bmw':
                    bmws_found += 1
                    range_bytes = range_cell[0].value
                    range_str = range_bytes.decode('utf-8')

                    if range_str == '':
                        continue

                    electric_range = int(range_str)

                    if electric_range > 100:
                        count += 1

            except (IndexError, KeyError, ValueError, AttributeError, UnicodeDecodeError) as e:
                continue 

        print(f"/Best-BMW processed {rows_processed} total rows, found {bmws_found} BMWs. Final count (>100 range): {count}")
        return str(count)
    except Exception as e:
        print(f"Error in /Best-BMW: {e}")
        return "Error processing request", 500


@app.route('/tesla-owners')
def get_tesla_owners_count():
    if not table: return "Error: Bigtable connection not established", 500
    print("Processing /tesla-owners request (Full Client-side filter)...")
    count = 0
    rows_processed = 0
    try:
        for row in table.read_rows():
            rows_processed += 1

            try:
                family_data = row.cells.get("ev_info", {})
                make_cell = family_data.get(b'make')
                city_cell = family_data.get(b'city')

                if not make_cell or not city_cell:
                    continue

                make = make_cell[0].value.decode('utf-8')
                city = city_cell[0].value.decode('utf-8')

                if make.lower() == 'tesla' and city.lower() == 'seattle':
                     count += 1

            except (IndexError, KeyError, AttributeError, UnicodeDecodeError) as e:
                continue 

        print(f"/tesla-owners processed {rows_processed} rows. Final count: {count}")
        return str(count)
    except Exception as e:
        print(f"Error in /tesla-owners: {e}")
        return "Error processing request", 500



@app.route('/update')
def update_vehicle_range():
    if not table: return "Error: Bigtable connection not established", 500
    print("Processing /update request...")
    row_key_to_update = b"257246118"
    new_range_value = b"200"
    try:
        row_mutation = table.direct_row(row_key_to_update)
        row_mutation.set_cell(
            "ev_info", b'electric range', new_range_value,
            timestamp=datetime.datetime.utcnow()
        )
        row_mutation.commit()
        print(f"Updated electric range for {row_key_to_update.decode('utf-8')}")
        return "Success"
    except Exception as e:
        print(f"Error in /update for row {row_key_to_update.decode('utf-8')}: {e}")
        return "Error processing update request", 500


@app.route('/delete')
def delete_old_vehicles_and_count():
    if not table: return "Error: Bigtable connection not established", 500
    print("Processing /delete request...")
    keys_to_delete = []
    rows_scanned_for_delete = 0
    min_year = 2014
    batch_size = 500
    try:
        print(f"Scanning for rows with model year < {min_year}...")
        scan_filter = ColumnQualifierRegexFilter(b'model year')
        for row in table.read_rows(filter_=scan_filter):
            rows_scanned_for_delete += 1
            cell = row.cells["ev_info"].get(b'model year')
            if cell:
                year_bytes = cell[0].value
                try:
                    model_year = int(year_bytes.decode('utf-8'))
                    if model_year < min_year:
                        keys_to_delete.append(row.row_key)
                except (ValueError, UnicodeDecodeError):
                     pass

        print(f"Identified {len(keys_to_delete)} rows to delete.")

        if keys_to_delete:
            print("Deleting rows in batches...")
            mutations_to_send = []
            for i, key in enumerate(keys_to_delete):
                row_mutation = table.direct_row(key)
                row_mutation.delete()
                mutations_to_send.append(row_mutation)
                if len(mutations_to_send) >= batch_size or i == len(keys_to_delete) - 1:
                    print(f"sending delete batch of {len(mutations_to_send)} rows...")
                    table.mutate_rows(mutations_to_send)
                    mutations_to_send = []
            print("Deletion complete.")
        else:
            print("No rows found matching deletion.")

        print("Counting remaining rows...")
        remaining_count = 0
        for _ in get_all_row_keys(table):
            remaining_count += 1
        print(f"/delete remaining count: {remaining_count}")
        return str(remaining_count)

    except Exception as e:
        print(f"Error in /delete: {e}")
        return "Error processing delete request", 500

# Run Flask App
if __name__ == '__main__':
    print("Starting Flask app on http://0.0.0.0:80")
    app.run(host='0.0.0.0', port=80, debug=False)
